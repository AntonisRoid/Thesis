{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join, abspath, dirname, realpath\n",
    "import sys\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date, timedelta\n",
    "from dateutil import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "import argparse\n",
    "import csv\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process\n",
    "\n",
    "from functools import partial\n",
    "from skopt import gp_minimize\n",
    "from skopt import space\n",
    "\n",
    "from functions import *\n",
    "from Train_bayes import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(data):\n",
    "    \n",
    "    data['date']=pd.to_datetime(data['date'])\n",
    "    data['migraine_start']=data['migraine_start'].astype(int)\n",
    "    data['order']=data['order'].astype(float).astype(int)\n",
    "    data['imputation']=data['imputation'].astype(float).astype(int)\n",
    "    data.loc[:, ['temp_avg','sun_perc','precip_tot',\n",
    "                  'pres_avg','cloud_avg','wind_avg','hum_avg',]] = data.loc[:, ['temp_avg','sun_perc','precip_tot','pres_avg',\n",
    "                  'cloud_avg','wind_avg','hum_avg',]].astype(float)\n",
    "    \n",
    "    data=data.sort_values(['order', 'date'])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a table with the predictions and the true values for the outcome variable\n",
    "def prd2(df_p,model):\n",
    "    predictions=[]\n",
    "    true_values=[]\n",
    "    orders=np.unique(df_p['order'])\n",
    "    #Processes every sequence individually\n",
    "    for o in orders:\n",
    "    \n",
    "        df_batch=df_p[df_p['order']==o]\n",
    "        df_batch=df_batch.sort_values(by='date')\n",
    "        df_batch.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        \n",
    "        X=df_batch.loc[:, ['temp_avg','sun_perc','precip_tot','pres_avg',\n",
    "                             'cloud_avg','wind_avg','hum_avg',]].to_numpy()\n",
    "        #resize for rnn keras use\n",
    "        X=np.resize(X,(X.shape[0],1,X.shape[1]))\n",
    "        \n",
    "        pred=model.predict(X,batch_size=1)\n",
    "        #reset state to clear memory\n",
    "        model.reset_states()\n",
    "       \n",
    "        pred=np.concatenate(pred).ravel()\n",
    "        \n",
    "        for number,j in enumerate(df_batch['imputation']):\n",
    "             if not j:\n",
    "                    predictions.append(pred[number])\n",
    "                    true_values.append(df_batch['migraine_start'][number])\n",
    "        \n",
    "    predictions=np.asarray(predictions)\n",
    "    true_values=np.asarray(true_values)\n",
    "    \n",
    "\n",
    "        \n",
    "    precision, recall, thresholds = precision_recall_curve(true_values, predictions)\n",
    "    auc_precision_recall=auc(recall, precision)\n",
    "    \n",
    "    auc_roc= round(roc_auc_score(true_values,predictions),3)\n",
    "    \n",
    "    return(predictions,true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3200bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of the model given the parameters and the cell type\n",
    "def modelcreation_bayes2(params,cell_type):\n",
    "    #batch_size, units, layers, dropout=params\n",
    "    units, layers, dropout=params\n",
    "    new_model = tf.keras.Sequential()\n",
    "    #adding every layer one by one\n",
    "    for i in range(layers):\n",
    "        if cell_type=='LSTM':\n",
    "            new_model.add(tf.keras.layers.LSTM(units, activation='tanh', return_sequences=True,\n",
    "                                       stateful=True, batch_input_shape=(1,1,7)))\n",
    "        elif cell_type=='GRU':\n",
    "            new_model.add(tf.keras.layers.GRU(units, activation='tanh', return_sequences=True,\n",
    "                                       stateful=True, batch_input_shape=(1,1,7)))\n",
    "            \n",
    "        if dropout!=0:\n",
    "            new_model.add(tf.keras.layers.Dropout(dropout*0.1))\n",
    "    #final layer with the outcome variable\n",
    "    new_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt=tf.keras.optimizers.Adam()\n",
    "    new_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training of the model and then it also makes predictions \n",
    "\n",
    "def fit_lstm2(df,df_test,params,cell_type,fold=None,epochs=1):\n",
    "\n",
    "    batch_size=1\n",
    "    # Since most days are not migraine days, the two classes are not balanced \n",
    "    class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.asarray([0,1]),\n",
    "                                                  y=df.loc[:,'migraine_start'])\n",
    "\n",
    "    weights = {i : class_weights[i] for i in range(2)}\n",
    "    \n",
    "    orders=np.unique(df['order'])\n",
    "    #creation of model\n",
    "    model=modelcreation_bayes2(params,cell_type=cell_type)\n",
    "    #loop for every epoch\n",
    "    for i in np.arange(epochs):\n",
    "        #print('epoch= ',i+1)\n",
    "        #every sequence one by one\n",
    "        for o in orders:\n",
    "            df_batch=df[df['order']==o]\n",
    "            df_batch=df_batch.sort_values(by='date')\n",
    "            df_batch.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            X=df_batch.loc[:, ['temp_avg','sun_perc','precip_tot','pres_avg',\n",
    "                             'cloud_avg','wind_avg','hum_avg',]].to_numpy()\n",
    "\n",
    "\n",
    "            X=np.resize(X,(X.shape[0],1,X.shape[1]))\n",
    "\n",
    "\n",
    "            Y=df_batch.loc[:,['migraine_start']]\n",
    "            #fit the same model for every sequence \n",
    "            model.fit(X,Y,epochs=1,batch_size=batch_size,shuffle=False, class_weight=weights, verbose=0)\n",
    "            #reseting states after every group of data so that different characteristics of every group do not influence next group\n",
    "            #and weather conditions of a previous group do not influence the predictions of the current group \n",
    "            model.reset_states() \n",
    "\n",
    "    train_scores['Train:']=prd2(df,model=model)\n",
    "    test_scores['Test:']=prd2(df_test,model=model)\n",
    "    return(prd2(df,model=model),prd2(df_test,model=model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946025c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args,cell_type):\n",
    "    \n",
    "    train = pd.read_csv('train_plus.csv', sep=',', index_col=False, dtype='unicode')#, error_bad_lines=False\n",
    "    \n",
    "    train = data_prep(train)\n",
    "    \n",
    "    test = pd.read_csv('test_plus.csv', sep=',', index_col=False, dtype='unicode')#, error_bad_lines=False\n",
    "    \n",
    "    test = data_prep(test)\n",
    "    \n",
    "    weather_full=pd.read_csv(\"weather_full.csv\")\n",
    "    weather_full['date']=pd.to_datetime(weather_full['date'])\n",
    "    weather_full.loc[:, ['temp_avg','sun_perc','precip_tot',\n",
    "                  'pres_avg','cloud_avg','wind_avg','hum_avg',]] = weather_full.loc[:, ['temp_avg','sun_perc','precip_tot','pres_avg',\n",
    "                  'cloud_avg','wind_avg','hum_avg',]].astype(float)\n",
    "    \n",
    "    \n",
    "    #Scaling of the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train.iloc[:,3:-2]=scaler.fit_transform(train.iloc[:,3:-2])\n",
    "    test.iloc[:,3:-2]=scaler.transform(test.iloc[:,3:-2])\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    train_values,test_values=fit_lstm2(train,test,args.params,cell_type=cell_type)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time:\"+str(int(end - start)))\n",
    "    return(train_values,test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    train_scores=mp.Manager().dict()\n",
    "    test_scores=mp.Manager().dict()\n",
    "    patient_scores=mp.Manager().dict()\n",
    "    #comment out for py file\n",
    "    #args=parse_args()\n",
    "    #turn this to a comment for py\n",
    "    random.seed(441995)\n",
    "    class args:\n",
    "        epochs=10\n",
    "        #comment out next line for lstm\n",
    "        params=39, 4, 4 \n",
    "        #comment out next line for gru\n",
    "        #params=10, 4, 2\n",
    "        \n",
    "    \n",
    "    #FOR LSTM\n",
    "    train_values,test_values=main(args,cell_type='LSTM')\n",
    "    (pd.DataFrame(train_values).T).to_csv('performance_lstm_train.zip', index=False)\n",
    "    (pd.DataFrame(test_values).T).to_csv('performance_lstm_test.zip', index=False)\n",
    "    \n",
    "    #COMMENT OUT FOR GRU\n",
    "    #train_values,test_values=main(args,cell_type='GRU')\n",
    "    #(pd.DataFrame(train_values).T).to_csv('performance_gru_train.zip', index=False)\n",
    "    #(pd.DataFrame(test_values).T).to_csv('performance_gru_test.zip', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR LSTM\n",
    "train_values_p = pd.read_csv('performance_lstm_train.zip', sep=',', index_col=False, dtype='unicode')\n",
    "test_values_p = pd.read_csv('performance_lstm_test.zip', sep=',', index_col=False, dtype='unicode')\n",
    "\n",
    "#COMMENT OUT FOR GUR\n",
    "#train_values_p = pd.read_csv('performance_gru_train.zip', sep=',', index_col=False, dtype='unicode')\n",
    "#test_values_p = pd.read_csv('performance_gru_test.zip', sep=',', index_col=False, dtype='unicode')\n",
    "\n",
    "train_values_p['1']=train_values_p['1'].astype(float).astype(int)\n",
    "train_values_p['0']=train_values_p['0'].astype(float)\n",
    "test_values_p['1']=test_values_p['1'].astype(float).astype(int)\n",
    "test_values_p['0']=test_values_p['0'].astype(float)\n",
    "(train_values_p).columns=['pred','real']\n",
    "(test_values_p).columns=['pred','real']\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(train_values_p['real'].to_numpy(), \n",
    "                                                       train_values_p['pred'].to_numpy())\n",
    "auc_pr_train=auc(recall, precision)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(test_values_p['real'].to_numpy(), \n",
    "                                                       test_values_p['pred'].to_numpy())\n",
    "auc_pr_test=auc(recall, precision)\n",
    "print(f'AUC PR: Test={round(auc_pr_test,3)}, Train={round(auc_pr_train,3)}')\n",
    "\n",
    "\n",
    "#training data: train_plus.csv\n",
    "\n",
    "train = pd.read_csv('train_plus.csv', sep=',', index_col=False, dtype='unicode')#, error_bad_lines=False\n",
    "train = data_prep(train)\n",
    "\n",
    "#testing data: test_plus.csv\n",
    "test = pd.read_csv('test_plus.csv', sep=',', index_col=False, dtype='unicode')#, error_bad_lines=False\n",
    "test = data_prep(test)\n",
    "\n",
    "real_train=train.loc[(train['imputation']==0)]\n",
    "pr_train=real_train.loc[real_train['migraine_start']==1].shape[0]/real_train.shape[0]\n",
    "real_test=test.loc[(test['imputation']==0)]\n",
    "pr_test=real_test.loc[real_test['migraine_start']==1].shape[0]/real_test.shape[0]\n",
    "\n",
    "print(f'Baseline Train AUC PR: {round(pr_train,3)}')\n",
    "print(f'Baseline Test AUC PR: {round(pr_test,3)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
